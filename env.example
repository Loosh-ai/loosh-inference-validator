# Loosh Inference Validator Configuration
# Copy this file to .env and update with your values

# =============================================================================
# Network Configuration
# =============================================================================
# NETUID: The subnet UID to connect to (78 for Loosh subnet on mainnet)
NETUID=78

# SUBTENSOR_NETWORK: Network name (finney=mainnet, test=testnet, local=local)
SUBTENSOR_NETWORK=finney

# SUBTENSOR_ADDRESS: Custom chain endpoint (RPC URL)
# You can specify your own subtensor node endpoint here
# Examples:
#   - Official Finney: wss://entrypoint-finney.opentensor.ai:443
#   - Custom node: ws://your_endpoint.your.network:9900
#   - Local node: ws://127.0.0.1:9944
SUBTENSOR_ADDRESS=wss://entrypoint-finney.opentensor.ai:443

# Network Configuration - testnet example
#NETUID=78
#SUBTENSOR_NETWORK=test
#SUBTENSOR_ADDRESS=wss://test.finney.opentensor.ai:443

# Network Configuration - custom endpoint example
#NETUID=78
#SUBTENSOR_NETWORK=finney
#SUBTENSOR_ADDRESS=ws://your_endpoint.your.network:9900

# =============================================================================
# Wallet Configuration
# =============================================================================
# Note: Fiber only supports wallets in ~/.bittensor/wallets
WALLET_NAME=validator
HOTKEY_NAME=validator

# =============================================================================
# Internal Configuration (NOT CONFIGURABLE VIA ENVIRONMENT)
# =============================================================================
# The following parameters are hard-coded in validator/internal_config.py
# for network consistency. They CANNOT be changed via environment variables.
# To modify these values, edit internal_config.py directly and redeploy.
#
# Miner Selection:
#   MIN_MINERS=3
#   MAX_MINERS=10
#   MIN_STAKE_THRESHOLD=100
#   MAX_MINER_STAKE=999
#
# Challenge Timing:
#   CHALLENGE_INTERVAL_SECONDS=300
#   CHALLENGE_TIMEOUT_SECONDS=120
#   EVALUATION_TIMEOUT_SECONDS=300
#
# Scoring:
#   SCORE_THRESHOLD=0.7
#
# Weight Setting:
#   WEIGHTS_INTERVAL_SECONDS=4320 (72 minutes)
#   WEIGHT_FRESHNESS_HOURS=3
#   WEIGHT_FRESHNESS_HOURS_DEGRADED=24
#   WEIGHT_MIN_SERVING_NODES=1
#
# Deregistration Safety:
#   DEREGISTRATION_BLOCK_LIMIT=5000
#   DEGRADED_MODE_THRESHOLD=4000
#   EMERGENCY_MODE_THRESHOLD=4500
#
# Metagraph:
#   METAGRAPH_REFRESH_INTERVAL_SECONDS=300
#
# LLM Behavior (challenge inference defaults):
#   DEFAULT_MODEL=mistralai/Mistral-7B-v0.1
#   DEFAULT_MAX_TOKENS=512
#   DEFAULT_TEMPERATURE=0.7
#   DEFAULT_TOP_P=0.95
#
# Embedding & Evaluation:
#   SENTENCE_TRANSFORMER_MODEL=sentence-transformers/all-MiniLM-L6-v2
#   ENABLE_NARRATIVE_GENERATION=true
#   ENABLE_HEATMAP_GENERATION=false
#   ENABLE_QUALITY_PLOTS=false
#
# Concurrency:
#   MAX_CONCURRENT_CHALLENGES=10
#   MAX_CONCURRENT_AVAILABILITY_CHECKS=20
#
# Fiber MLTS:
#   FIBER_KEY_TTL_SECONDS=3600
#   FIBER_HANDSHAKE_TIMEOUT_SECONDS=30
#   FIBER_ENABLE_KEY_ROTATION=true
#
# Sybil Penalty:
#   SYBIL_PENALTY_ENABLED=true
#   SYBIL_PENALTY_MAX=0.8
#   SYBIL_PENALTY_THRESHOLD=0.1
#   SYBIL_SAFETY_MAX_PENALIZED_FRACTION=0.33
#   SYBIL_SCORE_CACHE_TTL_SECONDS=300
#   SYBIL_SCORE_LOOKBACK_HOURS=168
#   REPORT_MINER_NETWORK_TO_CHALLENGE_API=true
#   MINER_NETWORK_REPORT_INTERVAL_SECONDS=3600
#   SYBIL_SCORE_CACHE_FRESHNESS_HOURS=6
#   REPORT_PENALTIES_TO_CHALLENGE_API=false
# =============================================================================

# =============================================================================
# Database Configuration
# =============================================================================
DB_PATH=validator.db
USERS_DB_PATH=users.db

# =============================================================================
# API Configuration
# =============================================================================
# REST API configuration for the validator API server
# IMPORTANT: This port MUST be publicly accessible for the Challenge API to push challenges
# The Challenge API sends encrypted challenges to POST /fiber/challenge on this API
# Note: you may need to change this to 127.0.0.1 depending on your deployment model. 
# Docker doesn't like 127.0.0.1 and so 0.0.0.0 is preferred in that case.
API_HOST=0.0.0.0
API_PORT=8000

# =============================================================================
# Axon Configuration (Bittensor Node Communication)
# =============================================================================
# Axon is the bittensor node's internal communication endpoint
# This is separate from the REST API above
#
# IMPORTANT: The axon port does NOT need public exposure
# Validators are clients that query miners - miners expose their axons, not validators
# Only change these if you have port conflicts or specific networking requirements
#
# AXON_IP: Internal IP address for the axon to bind to
# AXON_PORT: Internal port for the axon to bind to
# AXON_EXTERNAL_IP: External IP to advertise to the network (optional, auto-detected if not set)
# AXON_EXTERNAL_PORT: External port to advertise to the network (optional, uses AXON_PORT if not set)
# AXON_MAX_WORKERS: Maximum worker threads for handling axon requests
# AXON_TIMEOUT: Timeout for axon operations in seconds
AXON_IP=127.0.0.1
AXON_PORT=8099
#AXON_EXTERNAL_IP=
#AXON_EXTERNAL_PORT=
AXON_MAX_WORKERS=5
AXON_TIMEOUT=60

# =============================================================================
# Challenge API Configuration
# =============================================================================
CHALLENGE_API_URL=http://localhost:8080

# API key for Challenge API (fallback authentication)
# Primary authentication uses Fiber MLTS encryption.
# API key is used as fallback if Fiber handshake fails.
CHALLENGE_API_KEY=your-api-key

# Optional: API key for authenticating incoming challenge push requests
CHALLENGE_PUSH_API_KEY=

# =============================================================================
# Evaluation Configuration
# =============================================================================
# Deprecated: now uses CHALLENGE_API_URL
HEATMAP_UPLOAD_URL=http://localhost:8080/heatmap/upload

# =============================================================================
# LLM Configuration (for narrative generation - NOT CURRENTLY IN USE)
# =============================================================================
# Note: These settings are only used when ENABLE_NARRATIVE_GENERATION=true
# For production deployments with ENABLE_NARRATIVE_GENERATION=false, these are not needed
#
# IMPORTANT: The API endpoint must implement the OpenAI Chat Completions API format
# (see https://platform.openai.com/docs/api-reference/chat/create)
# The API interface must be compatible, but the underlying model does NOT need to be an OpenAI model.
# You can use any model (Llama, Qwen, Mistral, etc.) as long as the API follows OpenAI's format.
#
# Examples of compatible endpoints:
#   - OpenAI API (https://api.openai.com/v1/chat/completions)
#   - Azure OpenAI (https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions)
#   - vLLM (http://localhost:8000/v1/chat/completions)
#   - Ollama with OpenAI compatibility (http://localhost:11434/v1/chat/completions)
#   - Any endpoint that implements the OpenAI Chat Completions API format
#LLM_API_URL=
#LLM_API_KEY=
#LLM_MODEL=

# NOTE: LLM behavior params (DEFAULT_MODEL, DEFAULT_MAX_TOKENS, DEFAULT_TEMPERATURE,
# DEFAULT_TOP_P) and SENTENCE_TRANSFORMER_MODEL are now in internal_config.py.
# See "Internal Configuration" section above.

# =============================================================================
# Logging Configuration
# =============================================================================
LOG_LEVEL=INFO
LOG_FILE=

# =============================================================================
# Test Mode
# =============================================================================
# Enable test mode - picks first response without evaluation or heatmap generation
TEST_MODE=false

# NOTE: Feature flags (ENABLE_NARRATIVE_GENERATION, ENABLE_HEATMAP_GENERATION,
# ENABLE_QUALITY_PLOTS) are now in internal_config.py.
# See "Internal Configuration" section above.

# =============================================================================
# Challenge Mode Configuration
# =============================================================================
# Note: Only push mode is supported. Challenges are submitted via POST /challenges endpoint
# CHALLENGE_MODE=push  # Default and only supported mode

# NOTE: Concurrency params (MAX_CONCURRENT_CHALLENGES, MAX_CONCURRENT_AVAILABILITY_CHECKS)
# and Fiber MLTS params (FIBER_KEY_TTL_SECONDS, FIBER_HANDSHAKE_TIMEOUT_SECONDS,
# FIBER_ENABLE_KEY_ROTATION) are now in internal_config.py.
# See "Internal Configuration" section above.
